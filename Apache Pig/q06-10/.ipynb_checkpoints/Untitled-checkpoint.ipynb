{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\t{(b),(g),(f)}\t[jjj#3,bbb#0,ddd#9,ggg#8,hhh#2]\n",
      "A\t{(a),(f),(c)}\t[ccc#2,ddd#0,aaa#3,hhh#9]\n",
      "B\t{(f),(e),(a),(c)}\t[ddd#2,ggg#5,ccc#6,jjj#1]\n",
      "A\t{(a),(b)}\t[hhh#9,iii#5,eee#7,bbb#1]\n",
      "C\t{(f),(g),(d),(a)}\t[iii#6,ddd#5,eee#4,jjj#3]\n",
      "A\t{(c),(d)}\t[bbb#2,hhh#0,ccc#4,fff#1,aaa#7]\n",
      "A\t{(g),(d),(a)}\t[aaa#5,fff#8,ddd#2,iii#0,jjj#7,ccc#1]\n",
      "B\t{(b),(a)}\t[fff#3,hhh#1,ddd#2]\n",
      "E\t{(d),(e),(a),(f)}\t[eee#4,ccc#5,iii#9,fff#7,ggg#6,bbb#0]\n",
      "B\t{(d),(b),(g),(f)}\t[bbb#7,jjj#9,fff#5,iii#4,ggg#2,eee#3]\n"
     ]
    }
   ],
   "source": [
    "!head data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-18 16:53:52,881 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2021-05-18 16:53:53,417 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "Deleted output\n",
      "2021-05-18 16:53:54,519 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 16:53:54,968 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-05-18 16:53:54,970 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2021-05-18 16:53:55,008 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 16:53:55,013 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2021-05-18 16:53:55,037 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 16:53:55,049 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2021-05-18 16:53:55,330 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2021-05-18 16:53:55,345 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:53:55,373 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2021-05-18 16:53:55,467 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 16:53:55,619 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 16:53:55,698 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 16:53:55,890 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local179375990_0001\n",
      "2021-05-18 16:53:56,464 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356836072/pig-0.17.0-core-h2.jar <- /datalake/q06-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:53:56,478 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp904938283/tmp770161627/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621356836072/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:53:56,516 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356836073/automaton-1.11-8.jar <- /datalake/q06-10/automaton-1.11-8.jar\n",
      "2021-05-18 16:53:56,524 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp904938283/tmp1091551599/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621356836073/automaton-1.11-8.jar\n",
      "2021-05-18 16:53:56,525 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356836074/antlr-runtime-3.4.jar <- /datalake/q06-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:53:56,575 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp904938283/tmp-1650564945/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621356836074/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:53:56,576 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356836075/joda-time-2.9.3.jar <- /datalake/q06-10/joda-time-2.9.3.jar\n",
      "2021-05-18 16:53:56,583 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp904938283/tmp38820247/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621356836075/joda-time-2.9.3.jar\n",
      "2021-05-18 16:53:56,715 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356836072/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:53:56,715 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356836073/automaton-1.11-8.jar\n",
      "2021-05-18 16:53:56,715 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356836074/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:53:56,715 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356836075/joda-time-2.9.3.jar\n",
      "2021-05-18 16:53:56,723 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 16:53:56,728 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 16:53:56,812 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 16:53:56,814 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 16:53:56,815 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 16:53:56,816 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:53:56,817 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:53:56,818 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 16:53:56,904 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 16:53:56,905 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local179375990_0001_m_000000_0\n",
      "2021-05-18 16:53:57,074 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:53:57,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:53:57,126 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 16:53:57,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 16:53:57,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 16:53:57,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 16:53:57,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 16:53:57,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 16:53:57,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 16:53:57,262 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 16:53:57,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 16:53:57,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 16:53:57,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 16:53:57,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600\n",
      "2021-05-18 16:53:57,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213700(104854800); length = 697/6553600\n",
      "2021-05-18 16:53:57,634 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 16:53:57,639 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local179375990_0001_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 16:53:57,659 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 16:53:57,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local179375990_0001_m_000000_0' done.\n",
      "2021-05-18 16:53:57,667 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local179375990_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803019\n",
      "\t\tFILE: Number of bytes written=12097921\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=175\n",
      "\t\tMap output bytes=1925\n",
      "\t\tMap output materialized bytes=146\n",
      "\t\tInput split bytes=357\n",
      "\t\tCombine input records=175\n",
      "\t\tCombine output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=331350016\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 16:53:57,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local179375990_0001_m_000000_0\n",
      "2021-05-18 16:53:57,668 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 16:53:57,682 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 16:53:57,682 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local179375990_0001_r_000000_0\n",
      "2021-05-18 16:53:57,778 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:53:57,778 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:53:57,783 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 16:53:57,793 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22774951\n",
      "2021-05-18 16:53:57,826 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 16:53:57,842 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local179375990_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 16:53:57,940 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local179375990_0001_m_000000_0 decomp: 142 len: 146 to MEMORY\n",
      "2021-05-18 16:53:57,959 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 142 bytes from map-output for attempt_local179375990_0001_m_000000_0\n",
      "2021-05-18 16:53:57,962 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 142, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->142\n",
      "2021-05-18 16:53:57,965 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 16:53:57,974 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:53:57,978 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 16:53:58,017 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 16:53:58,018 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 134 bytes\n",
      "2021-05-18 16:53:58,023 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 142 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 16:53:58,026 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 146 bytes from disk\n",
      "2021-05-18 16:53:58,029 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 16:53:58,029 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 16:53:58,030 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 134 bytes\n",
      "2021-05-18 16:53:58,031 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:53:58,076 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:53:58,076 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:53:58,288 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2021-05-18 16:53:58,313 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local179375990_0001_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 16:53:58,354 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:53:58,354 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local179375990_0001_r_000000_0 is allowed to commit now\n",
      "2021-05-18 16:53:58,440 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local179375990_0001_r_000000_0' to file:/datalake/q06-10/output/_temporary/0/task_local179375990_0001_r_000000\n",
      "2021-05-18 16:53:58,442 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 16:53:58,442 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local179375990_0001_r_000000_0' done.\n",
      "2021-05-18 16:53:58,443 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local179375990_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803343\n",
      "\t\tFILE: Number of bytes written=12098149\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=146\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=331350016\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 16:53:58,443 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local179375990_0001_r_000000_0\n",
      "2021-05-18 16:53:58,443 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 16:54:01,770 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:01,842 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:01,843 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2021-05-18 16:54:01,846 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:01,937 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:01,941 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:01,943 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!pig -execute 'run question.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa,13\n",
      "bbb,16\n",
      "ccc,23\n",
      "ddd,23\n",
      "eee,15\n",
      "fff,20\n",
      "ggg,13\n",
      "hhh,16\n",
      "iii,18\n",
      "jjj,18\n"
     ]
    }
   ],
   "source": [
    "cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-18 16:54:25,401 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2021-05-18 16:54:25,923 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "2021-05-18 16:54:27,141 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 16:54:27,659 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-05-18 16:54:27,660 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2021-05-18 16:54:27,702 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 16:54:27,712 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2021-05-18 16:54:27,732 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 16:54:27,746 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2021-05-18 16:54:28,015 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2021-05-18 16:54:28,030 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:28,053 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2021-05-18 16:54:28,151 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 16:54:28,276 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 16:54:28,326 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 16:54:28,517 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1928895678_0001\n",
      "2021-05-18 16:54:28,976 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356868686/pig-0.17.0-core-h2.jar <- /datalake/q06-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:54:29,010 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-978839320/tmp591259229/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621356868686/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:54:29,115 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356868687/automaton-1.11-8.jar <- /datalake/q06-10/automaton-1.11-8.jar\n",
      "2021-05-18 16:54:29,122 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-978839320/tmp1445672969/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621356868687/automaton-1.11-8.jar\n",
      "2021-05-18 16:54:29,123 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356868688/antlr-runtime-3.4.jar <- /datalake/q06-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:54:29,131 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-978839320/tmp221090948/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621356868688/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:54:29,132 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621356868689/joda-time-2.9.3.jar <- /datalake/q06-10/joda-time-2.9.3.jar\n",
      "2021-05-18 16:54:29,138 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-978839320/tmp-1994983908/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621356868689/joda-time-2.9.3.jar\n",
      "2021-05-18 16:54:29,232 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356868686/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 16:54:29,232 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356868687/automaton-1.11-8.jar\n",
      "2021-05-18 16:54:29,232 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356868688/antlr-runtime-3.4.jar\n",
      "2021-05-18 16:54:29,232 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621356868689/joda-time-2.9.3.jar\n",
      "2021-05-18 16:54:29,239 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 16:54:29,243 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 16:54:29,323 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 16:54:29,326 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 16:54:29,326 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 16:54:29,328 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:54:29,328 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:54:29,329 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 16:54:29,422 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 16:54:29,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1928895678_0001_m_000000_0\n",
      "2021-05-18 16:54:29,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:54:29,511 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:54:29,535 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 16:54:29,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 16:54:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 16:54:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 16:54:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 16:54:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 16:54:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 16:54:29,648 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 16:54:29,795 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 16:54:29,795 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 16:54:29,795 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 16:54:29,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600\n",
      "2021-05-18 16:54:29,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213700(104854800); length = 697/6553600\n",
      "2021-05-18 16:54:29,907 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 16:54:29,914 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1928895678_0001_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 16:54:29,935 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 16:54:29,935 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1928895678_0001_m_000000_0' done.\n",
      "2021-05-18 16:54:29,944 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1928895678_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803019\n",
      "\t\tFILE: Number of bytes written=12099935\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=175\n",
      "\t\tMap output bytes=1925\n",
      "\t\tMap output materialized bytes=146\n",
      "\t\tInput split bytes=357\n",
      "\t\tCombine input records=175\n",
      "\t\tCombine output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=338690048\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 16:54:29,945 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1928895678_0001_m_000000_0\n",
      "2021-05-18 16:54:29,945 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 16:54:29,959 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 16:54:29,965 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1928895678_0001_r_000000_0\n",
      "2021-05-18 16:54:30,035 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:54:30,035 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:54:30,050 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 16:54:30,062 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@220e3adf\n",
      "2021-05-18 16:54:30,121 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 16:54:30,125 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1928895678_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 16:54:30,255 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1928895678_0001_m_000000_0 decomp: 142 len: 146 to MEMORY\n",
      "2021-05-18 16:54:30,261 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 142 bytes from map-output for attempt_local1928895678_0001_m_000000_0\n",
      "2021-05-18 16:54:30,293 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 142, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->142\n",
      "2021-05-18 16:54:30,296 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 16:54:30,297 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:54:30,298 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 16:54:30,322 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 16:54:30,322 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 134 bytes\n",
      "2021-05-18 16:54:30,325 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 142 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 16:54:30,326 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 146 bytes from disk\n",
      "2021-05-18 16:54:30,327 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 16:54:30,327 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 16:54:30,328 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 134 bytes\n",
      "2021-05-18 16:54:30,329 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:54:30,345 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 16:54:30,345 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 16:54:30,640 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2021-05-18 16:54:30,657 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1928895678_0001_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 16:54:30,714 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 16:54:30,714 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1928895678_0001_r_000000_0 is allowed to commit now\n",
      "2021-05-18 16:54:30,794 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1928895678_0001_r_000000_0' to file:/datalake/q06-10/output/_temporary/0/task_local1928895678_0001_r_000000\n",
      "2021-05-18 16:54:30,796 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 16:54:30,797 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1928895678_0001_r_000000_0' done.\n",
      "2021-05-18 16:54:30,798 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1928895678_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803343\n",
      "\t\tFILE: Number of bytes written=12100163\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=146\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=338690048\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 16:54:30,798 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1928895678_0001_r_000000_0\n",
      "2021-05-18 16:54:30,798 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 16:54:34,291 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:34,327 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:34,328 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2021-05-18 16:54:34,330 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:34,405 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:34,407 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 16:54:34,408 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

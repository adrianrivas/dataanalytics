{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,Vivian,Hamilton,1971-07-08,green,1\n",
      "2,Karen,Holcomb,1974-05-23,green,4\n",
      "3,Cody,Garrett,1973-04-22,orange,1\n",
      "4,Roth,Fry,1975-01-29,black,1\n",
      "5,Zoe,Conway,1974-07-03,blue,2\n",
      "6,Gretchen,Kinney,1974-10-18,viole,1\n",
      "7,Driscoll,Klein,1970-10-05,blue,5\n",
      "8,Karyn,Diaz,1969-02-24,red,1\n",
      "9,Merritt,Guy,1974-10-17,indigo,4\n",
      "10,Kylan,Sexton,1975-02-28,black,4\n"
     ]
    }
   ],
   "source": [
    "!head data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-18 19:32:33,503 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2021-05-18 19:32:35,177 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-05-18 19:32:35,178 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2021-05-18 19:32:35,224 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:32:35,230 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2021-05-18 19:32:35,249 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2021-05-18 19:32:35,410 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2021-05-18 19:32:35,423 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:35,443 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2021-05-18 19:32:35,522 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:32:35,646 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:32:35,689 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:32:35,843 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local679223554_0001\n",
      "2021-05-18 19:32:36,261 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366355990/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:36,307 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp880448354/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366355990/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:36,360 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366355991/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:36,380 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp440483256/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366355991/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:36,381 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366355992/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:36,397 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-1247773805/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366355992/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:36,399 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366355993/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:36,404 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-1207356710/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366355993/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:36,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366355990/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:36,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366355991/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:36,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366355992/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:36,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366355993/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:36,525 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:32:36,545 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:32:36,612 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:32:36,617 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:36,618 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:36,618 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:32:36,692 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:32:36,693 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local679223554_0001_m_000000_0\n",
      "2021-05-18 19:32:36,779 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:36,779 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:36,830 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:32:36,845 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 632\n",
      "Input split[0]:\n",
      "   Length = 632\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:32:36,897 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:36,897 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:36,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:32:36,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local679223554_0001_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:32:37,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:32:37,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local679223554_0001_m_000000_0 is allowed to commit now\n",
      "2021-05-18 19:32:37,014 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local679223554_0001_m_000000_0' to file:/tmp/temp-890728749/tmp-1926441048/_temporary/0/task_local679223554_0001_m_000000\n",
      "2021-05-18 19:32:37,015 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:32:37,016 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local679223554_0001_m_000000_0' done.\n",
      "2021-05-18 19:32:37,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local679223554_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801871\n",
      "\t\tFILE: Number of bytes written=12062784\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tInput split bytes=357\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=320864256\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:32:37,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local679223554_0001_m_000000_0\n",
      "2021-05-18 19:32:37,046 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:32:41,563 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:41,578 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:41,578 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2021-05-18 19:32:41,578 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:32:41,580 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:41,738 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:41,751 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:32:41,829 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:32:41,835 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:32:41,851 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local342771945_0002\n",
      "2021-05-18 19:32:42,017 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366361902/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:42,022 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-578468314/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366361902/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:42,023 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366361903/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:42,035 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp2050547557/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366361903/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:42,036 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366361904/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:42,040 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-2048705094/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366361904/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:42,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366361905/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:42,047 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-302969024/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366361905/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:42,116 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366361902/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:42,116 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366361903/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:42,116 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366361904/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:42,116 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366361905/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:42,117 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:32:42,117 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:32:42,133 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:32:42,133 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:32:42,134 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:42,134 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:42,134 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:32:42,139 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:32:42,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local342771945_0002_m_000000_0\n",
      "2021-05-18 19:32:42,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:42,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:42,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:32:42,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 223\n",
      "Input split[0]:\n",
      "   Length = 223\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:32:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 19:32:42,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 19:32:42,230 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 19:32:42,231 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 19:32:42,231 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 19:32:42,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 19:32:42,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:32:42,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 19:32:42,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 19:32:42,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 518; bufvoid = 104857600\n",
      "2021-05-18 19:32:42,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2021-05-18 19:32:42,310 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 19:32:42,317 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local342771945_0002_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:32:42,323 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:32:42,324 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local342771945_0002_m_000000_0' done.\n",
      "2021-05-18 19:32:42,324 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local342771945_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603370\n",
      "\t\tFILE: Number of bytes written=24143948\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=518\n",
      "\t\tMap output materialized bytes=560\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=387448832\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 19:32:42,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local342771945_0002_m_000000_0\n",
      "2021-05-18 19:32:42,325 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:32:42,329 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 19:32:42,329 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local342771945_0002_r_000000_0\n",
      "2021-05-18 19:32:42,361 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:42,361 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:42,367 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:32:42,371 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5fa1aaad\n",
      "2021-05-18 19:32:42,401 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 19:32:42,417 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local342771945_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 19:32:42,500 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local342771945_0002_m_000000_0 decomp: 556 len: 560 to MEMORY\n",
      "2021-05-18 19:32:42,506 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 556 bytes from map-output for attempt_local342771945_0002_m_000000_0\n",
      "2021-05-18 19:32:42,509 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 556, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->556\n",
      "2021-05-18 19:32:42,512 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 19:32:42,514 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:42,515 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 19:32:42,526 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:32:42,526 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 537 bytes\n",
      "2021-05-18 19:32:42,529 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 556 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 19:32:42,530 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 560 bytes from disk\n",
      "2021-05-18 19:32:42,531 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 19:32:42,531 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:32:42,533 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 537 bytes\n",
      "2021-05-18 19:32:42,533 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:42,548 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:42,548 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:42,550 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2021-05-18 19:32:42,615 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local342771945_0002_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:32:42,620 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:42,620 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local342771945_0002_r_000000_0 is allowed to commit now\n",
      "2021-05-18 19:32:42,624 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local342771945_0002_r_000000_0' to file:/tmp/temp-890728749/tmp99801559/_temporary/0/task_local342771945_0002_r_000000\n",
      "2021-05-18 19:32:42,630 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 19:32:42,631 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local342771945_0002_r_000000_0' done.\n",
      "2021-05-18 19:32:42,633 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local342771945_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604522\n",
      "\t\tFILE: Number of bytes written=24144576\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=560\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=387448832\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:32:42,634 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local342771945_0002_r_000000_0\n",
      "2021-05-18 19:32:42,634 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 19:32:47,248 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:47,251 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:47,252 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:47,422 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:47,434 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:32:47,544 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:32:47,551 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:32:47,621 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1969787722_0003\n",
      "2021-05-18 19:32:47,910 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366367723/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:47,920 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-557247237/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366367723/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:47,921 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366367724/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:47,933 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-1505642715/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366367724/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:47,938 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366367725/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:47,954 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp1756252856/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366367725/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:47,955 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366367726/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:47,962 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp-203024126/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366367726/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:47,963 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366367727/tmp99801559 <- /datalake/q11-10/pigsample_842588842_1621366367382\n",
      "2021-05-18 19:32:47,970 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-890728749/tmp99801559 as file:/tmp/hadoop-root/mapred/local/1621366367727/tmp99801559\n",
      "2021-05-18 19:32:48,133 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366367723/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:32:48,134 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366367724/automaton-1.11-8.jar\n",
      "2021-05-18 19:32:48,134 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366367725/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:32:48,134 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366367726/joda-time-2.9.3.jar\n",
      "2021-05-18 19:32:48,135 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:32:48,136 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:32:48,169 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:32:48,169 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:32:48,170 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:48,170 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:48,171 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:32:48,185 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:32:48,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1969787722_0003_m_000000_0\n",
      "2021-05-18 19:32:48,225 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:48,226 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:48,226 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:32:48,230 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 223\n",
      "Input split[0]:\n",
      "   Length = 223\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:32:48,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 19:32:48,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 19:32:48,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 19:32:48,316 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 19:32:48,317 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 19:32:48,318 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 19:32:48,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:32:48,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 19:32:48,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 19:32:48,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 205; bufvoid = 104857600\n",
      "2021-05-18 19:32:48,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2021-05-18 19:32:48,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 19:32:48,360 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1969787722_0003_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:32:48,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:32:48,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1969787722_0003_m_000000_0' done.\n",
      "2021-05-18 19:32:48,377 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1969787722_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406105\n",
      "\t\tFILE: Number of bytes written=36226748\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=205\n",
      "\t\tMap output materialized bytes=247\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=42\n",
      "\t\tTotal committed heap usage (bytes)=406847488\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 19:32:48,377 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1969787722_0003_m_000000_0\n",
      "2021-05-18 19:32:48,377 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:32:48,390 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 19:32:48,390 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1969787722_0003_r_000000_0\n",
      "2021-05-18 19:32:48,431 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:48,432 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:48,446 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:32:48,447 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20575ae5\n",
      "2021-05-18 19:32:48,448 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 19:32:48,462 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1969787722_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 19:32:48,482 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1969787722_0003_m_000000_0 decomp: 243 len: 247 to MEMORY\n",
      "2021-05-18 19:32:48,484 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 243 bytes from map-output for attempt_local1969787722_0003_m_000000_0\n",
      "2021-05-18 19:32:48,500 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 243, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->243\n",
      "2021-05-18 19:32:48,502 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2021-05-18 19:32:48,502 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 19:32:48,506 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:48,506 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 19:32:48,532 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:32:48,532 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 233 bytes\n",
      "2021-05-18 19:32:48,534 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 243 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 19:32:48,535 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 247 bytes from disk\n",
      "2021-05-18 19:32:48,535 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 19:32:48,535 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:32:48,544 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 233 bytes\n",
      "2021-05-18 19:32:48,544 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:48,552 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:32:48,553 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:32:48,603 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1969787722_0003_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:32:48,619 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:32:48,619 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1969787722_0003_r_000000_0 is allowed to commit now\n",
      "2021-05-18 19:32:48,623 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1969787722_0003_r_000000_0' to file:/tmp/temp-890728749/tmp66469027/_temporary/0/task_local1969787722_0003_r_000000\n",
      "2021-05-18 19:32:48,625 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 19:32:48,625 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1969787722_0003_r_000000_0' done.\n",
      "2021-05-18 19:32:48,636 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1969787722_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406631\n",
      "\t\tFILE: Number of bytes written=36227536\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=18\n",
      "\t\tReduce shuffle bytes=247\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=18\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=406847488\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:32:48,637 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1969787722_0003_r_000000_0\n",
      "2021-05-18 19:32:48,637 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 19:32:53,161 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,164 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,167 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,194 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,196 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,197 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,206 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,208 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,210 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,219 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,220 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,221 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:32:53,238 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(Boyer,BOYER,boyer)\n",
      "(Coffey,COFFEY,coffey)\n",
      "(Conway,CONWAY,conway)\n",
      "(Crane,CRANE,crane)\n",
      "(Diaz,DIAZ,diaz)\n",
      "(Estes,ESTES,estes)\n",
      "(Fry,FRY,fry)\n",
      "(Garrett,GARRETT,garrett)\n",
      "(Guy,GUY,guy)\n",
      "(Hamilton,HAMILTON,hamilton)\n",
      "(Holcomb,HOLCOMB,holcomb)\n",
      "(Jarvis,JARVIS,jarvis)\n",
      "(Kinney,KINNEY,kinney)\n",
      "(Klein,KLEIN,klein)\n",
      "(Knight,KNIGHT,knight)\n",
      "(Noel,NOEL,noel)\n",
      "(Sexton,SEXTON,sexton)\n",
      "(Silva,SILVA,silva)\n"
     ]
    }
   ],
   "source": [
    "!pig -execute 'run question.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-18 19:34:49,383 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2021-05-18 19:34:51,466 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 19:34:52,134 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-05-18 19:34:52,136 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2021-05-18 19:34:52,233 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:34:52,238 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2021-05-18 19:34:52,274 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2021-05-18 19:34:52,613 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2021-05-18 19:34:52,649 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:34:52,689 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2021-05-18 19:34:52,831 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:34:53,034 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:34:53,103 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:34:53,276 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1082492961_0001\n",
      "2021-05-18 19:34:53,899 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366493460/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:53,919 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-663950806/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366493460/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:53,921 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366493461/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:53,927 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-704141365/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366493461/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:53,928 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366493462/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:53,953 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-684581477/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366493462/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:53,955 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366493463/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:53,963 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp412881652/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366493463/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:54,054 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366493460/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:54,055 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366493461/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:54,055 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366493462/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:54,055 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366493463/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:54,065 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:34:54,081 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:34:54,143 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:34:54,148 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:54,148 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:54,149 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:34:54,222 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:34:54,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1082492961_0001_m_000000_0\n",
      "2021-05-18 19:34:54,323 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:54,324 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:54,369 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:34:54,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 632\n",
      "Input split[0]:\n",
      "   Length = 632\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:34:54,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:54,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:54,511 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:34:54,511 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1082492961_0001_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:34:54,536 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:34:54,536 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1082492961_0001_m_000000_0 is allowed to commit now\n",
      "2021-05-18 19:34:54,543 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1082492961_0001_m_000000_0' to file:/tmp/temp64282880/tmp126574299/_temporary/0/task_local1082492961_0001_m_000000\n",
      "2021-05-18 19:34:54,545 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:34:54,545 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1082492961_0001_m_000000_0' done.\n",
      "2021-05-18 19:34:54,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1082492961_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801871\n",
      "\t\tFILE: Number of bytes written=12065110\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tInput split bytes=357\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=318767104\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:34:54,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1082492961_0001_m_000000_0\n",
      "2021-05-18 19:34:54,560 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:34:59,092 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:34:59,110 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:34:59,111 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2021-05-18 19:34:59,111 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:34:59,113 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:34:59,278 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:34:59,289 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:34:59,345 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:34:59,349 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:34:59,364 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local971725262_0002\n",
      "2021-05-18 19:34:59,560 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366499420/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:59,565 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp1842892533/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366499420/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:59,566 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366499421/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:59,577 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-695593542/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366499421/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:59,578 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366499422/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:59,585 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-109922634/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366499422/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:59,586 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366499423/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:59,591 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-1357070805/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366499423/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:59,649 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366499420/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:34:59,649 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366499421/automaton-1.11-8.jar\n",
      "2021-05-18 19:34:59,649 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366499422/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:34:59,649 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366499423/joda-time-2.9.3.jar\n",
      "2021-05-18 19:34:59,650 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:34:59,651 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:34:59,669 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:34:59,670 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:34:59,670 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:59,670 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:59,671 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:34:59,677 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:34:59,678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local971725262_0002_m_000000_0\n",
      "2021-05-18 19:34:59,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:59,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:59,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:34:59,707 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 223\n",
      "Input split[0]:\n",
      "   Length = 223\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:34:59,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 19:34:59,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 19:34:59,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 19:34:59,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 19:34:59,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 19:34:59,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 19:34:59,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:34:59,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 19:34:59,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 19:34:59,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 518; bufvoid = 104857600\n",
      "2021-05-18 19:34:59,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2021-05-18 19:34:59,908 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 19:34:59,916 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local971725262_0002_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:34:59,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:34:59,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local971725262_0002_m_000000_0' done.\n",
      "2021-05-18 19:34:59,924 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local971725262_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603366\n",
      "\t\tFILE: Number of bytes written=24146640\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=518\n",
      "\t\tMap output materialized bytes=560\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=34\n",
      "\t\tTotal committed heap usage (bytes)=384827392\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 19:34:59,924 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local971725262_0002_m_000000_0\n",
      "2021-05-18 19:34:59,924 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:34:59,929 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 19:34:59,929 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local971725262_0002_r_000000_0\n",
      "2021-05-18 19:34:59,958 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:34:59,959 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:34:59,969 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:34:59,974 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3bd0ca21\n",
      "2021-05-18 19:35:00,039 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 19:35:00,055 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local971725262_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 19:35:00,192 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local971725262_0002_m_000000_0 decomp: 556 len: 560 to MEMORY\n",
      "2021-05-18 19:35:00,203 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 556 bytes from map-output for attempt_local971725262_0002_m_000000_0\n",
      "2021-05-18 19:35:00,217 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 556, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->556\n",
      "2021-05-18 19:35:00,222 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 19:35:00,232 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:00,232 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 19:35:00,251 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:35:00,251 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 537 bytes\n",
      "2021-05-18 19:35:00,254 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 556 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 19:35:00,254 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 560 bytes from disk\n",
      "2021-05-18 19:35:00,255 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 19:35:00,256 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:35:00,268 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 537 bytes\n",
      "2021-05-18 19:35:00,269 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:00,301 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:35:00,301 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:35:00,315 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2021-05-18 19:35:00,416 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local971725262_0002_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:35:00,421 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:00,422 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local971725262_0002_r_000000_0 is allowed to commit now\n",
      "2021-05-18 19:35:00,426 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local971725262_0002_r_000000_0' to file:/tmp/temp64282880/tmp2038920913/_temporary/0/task_local971725262_0002_r_000000\n",
      "2021-05-18 19:35:00,428 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 19:35:00,428 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local971725262_0002_r_000000_0' done.\n",
      "2021-05-18 19:35:00,429 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local971725262_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604518\n",
      "\t\tFILE: Number of bytes written=24147268\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=560\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=384827392\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:35:00,429 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local971725262_0002_r_000000_0\n",
      "2021-05-18 19:35:00,429 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 19:35:04,801 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:04,806 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:04,808 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:04,930 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:04,939 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-05-18 19:35:05,014 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-05-18 19:35:05,018 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-05-18 19:35:05,041 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2071654304_0003\n",
      "2021-05-18 19:35:05,299 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366505108/pig-0.17.0-core-h2.jar <- /datalake/q11-10/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:35:05,305 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp382012284/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1621366505108/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:35:05,306 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366505109/automaton-1.11-8.jar <- /datalake/q11-10/automaton-1.11-8.jar\n",
      "2021-05-18 19:35:05,312 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp424693766/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1621366505109/automaton-1.11-8.jar\n",
      "2021-05-18 19:35:05,313 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366505110/antlr-runtime-3.4.jar <- /datalake/q11-10/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:35:05,317 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp-2081711652/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1621366505110/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:35:05,318 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366505111/joda-time-2.9.3.jar <- /datalake/q11-10/joda-time-2.9.3.jar\n",
      "2021-05-18 19:35:05,323 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp152731343/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1621366505111/joda-time-2.9.3.jar\n",
      "2021-05-18 19:35:05,324 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1621366505112/tmp2038920913 <- /datalake/q11-10/pigsample_803685654_1621366504908\n",
      "2021-05-18 19:35:05,329 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp64282880/tmp2038920913 as file:/tmp/hadoop-root/mapred/local/1621366505112/tmp2038920913\n",
      "2021-05-18 19:35:05,412 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366505108/pig-0.17.0-core-h2.jar\n",
      "2021-05-18 19:35:05,412 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366505109/automaton-1.11-8.jar\n",
      "2021-05-18 19:35:05,412 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366505110/antlr-runtime-3.4.jar\n",
      "2021-05-18 19:35:05,412 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1621366505111/joda-time-2.9.3.jar\n",
      "2021-05-18 19:35:05,413 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2021-05-18 19:35:05,413 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2021-05-18 19:35:05,427 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-05-18 19:35:05,429 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-05-18 19:35:05,435 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-05-18 19:35:05,436 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:35:05,436 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:35:05,436 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2021-05-18 19:35:05,467 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2021-05-18 19:35:05,468 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2071654304_0003_m_000000_0\n",
      "2021-05-18 19:35:05,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:35:05,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:35:05,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:35:05,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 223\n",
      "Input split[0]:\n",
      "   Length = 223\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2021-05-18 19:35:05,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2021-05-18 19:35:05,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2021-05-18 19:35:05,545 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2021-05-18 19:35:05,545 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2021-05-18 19:35:05,545 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2021-05-18 19:35:05,547 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2021-05-18 19:35:05,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2021-05-18 19:35:05,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2021-05-18 19:35:05,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2021-05-18 19:35:05,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 205; bufvoid = 104857600\n",
      "2021-05-18 19:35:05,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2021-05-18 19:35:05,556 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2021-05-18 19:35:05,562 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2071654304_0003_m_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:35:05,568 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2021-05-18 19:35:05,568 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2071654304_0003_m_000000_0' done.\n",
      "2021-05-18 19:35:05,571 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2071654304_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406097\n",
      "\t\tFILE: Number of bytes written=36230022\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=205\n",
      "\t\tMap output materialized bytes=247\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=25\n",
      "\t\tTotal committed heap usage (bytes)=403701760\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2021-05-18 19:35:05,571 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2071654304_0003_m_000000_0\n",
      "2021-05-18 19:35:05,572 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2021-05-18 19:35:05,575 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2021-05-18 19:35:05,576 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2071654304_0003_r_000000_0\n",
      "2021-05-18 19:35:05,600 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:35:05,601 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:35:05,604 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-05-18 19:35:05,605 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a41a2ef\n",
      "2021-05-18 19:35:05,611 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2021-05-18 19:35:05,615 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2071654304_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2021-05-18 19:35:05,626 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local2071654304_0003_m_000000_0 decomp: 243 len: 247 to MEMORY\n",
      "2021-05-18 19:35:05,635 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 243 bytes from map-output for attempt_local2071654304_0003_m_000000_0\n",
      "2021-05-18 19:35:05,637 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 243, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->243\n",
      "2021-05-18 19:35:05,638 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2021-05-18 19:35:05,639 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2021-05-18 19:35:05,640 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:05,644 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2021-05-18 19:35:05,646 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:35:05,647 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 233 bytes\n",
      "2021-05-18 19:35:05,649 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 243 bytes to disk to satisfy reduce memory limit\n",
      "2021-05-18 19:35:05,649 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 247 bytes from disk\n",
      "2021-05-18 19:35:05,649 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2021-05-18 19:35:05,649 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2021-05-18 19:35:05,655 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 233 bytes\n",
      "2021-05-18 19:35:05,656 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:05,659 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2021-05-18 19:35:05,659 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-05-18 19:35:05,787 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2071654304_0003_r_000000_0 is done. And is in the process of committing\n",
      "2021-05-18 19:35:05,819 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2021-05-18 19:35:05,819 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local2071654304_0003_r_000000_0 is allowed to commit now\n",
      "2021-05-18 19:35:05,901 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2071654304_0003_r_000000_0' to file:/datalake/q11-10/output/_temporary/0/task_local2071654304_0003_r_000000\n",
      "2021-05-18 19:35:05,903 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2021-05-18 19:35:05,903 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2071654304_0003_r_000000_0' done.\n",
      "2021-05-18 19:35:05,903 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2071654304_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406623\n",
      "\t\tFILE: Number of bytes written=36230626\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=18\n",
      "\t\tReduce shuffle bytes=247\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=18\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=403701760\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2021-05-18 19:35:05,904 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2071654304_0003_r_000000_0\n",
      "2021-05-18 19:35:05,904 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2021-05-18 19:35:10,440 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,446 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,454 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,478 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,479 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,481 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,490 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,492 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,493 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,500 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,502 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2021-05-18 19:35:10,503 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
